{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7514299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gurobi, CSV, DataFrames, JuMP, LinearAlgebra, Distributions, Random, GLMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3718a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Column1</th></tr><tr><th></th><th>Float64</th></tr></thead><tbody><p>4,474 rows × 1 columns</p><tr><th>1</th><td>1023.33</td></tr><tr><th>2</th><td>311.594</td></tr><tr><th>3</th><td>351.542</td></tr><tr><th>4</th><td>1609.9</td></tr><tr><th>5</th><td>1078.6</td></tr><tr><th>6</th><td>386.83</td></tr><tr><th>7</th><td>203.735</td></tr><tr><th>8</th><td>564.598</td></tr><tr><th>9</th><td>107.86</td></tr><tr><th>10</th><td>1070.61</td></tr><tr><th>11</th><td>1062.62</td></tr><tr><th>12</th><td>910.814</td></tr><tr><th>13</th><td>1609.9</td></tr><tr><th>14</th><td>1454.11</td></tr><tr><th>15</th><td>2940.17</td></tr><tr><th>16</th><td>3661.9</td></tr><tr><th>17</th><td>3197.17</td></tr><tr><th>18</th><td>3115.94</td></tr><tr><th>19</th><td>337.561</td></tr><tr><th>20</th><td>1831.62</td></tr><tr><th>21</th><td>162.455</td></tr><tr><th>22</th><td>1655.18</td></tr><tr><th>23</th><td>2133.22</td></tr><tr><th>24</th><td>539.298</td></tr><tr><th>25</th><td>2999.43</td></tr><tr><th>26</th><td>227.704</td></tr><tr><th>27</th><td>211.724</td></tr><tr><th>28</th><td>143.813</td></tr><tr><th>29</th><td>294.284</td></tr><tr><th>30</th><td>3151.9</td></tr><tr><th>&vellip;</th><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|c}\n",
       "\t& Column1\\\\\n",
       "\t\\hline\n",
       "\t& Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1023.33 \\\\\n",
       "\t2 & 311.594 \\\\\n",
       "\t3 & 351.542 \\\\\n",
       "\t4 & 1609.9 \\\\\n",
       "\t5 & 1078.6 \\\\\n",
       "\t6 & 386.83 \\\\\n",
       "\t7 & 203.735 \\\\\n",
       "\t8 & 564.598 \\\\\n",
       "\t9 & 107.86 \\\\\n",
       "\t10 & 1070.61 \\\\\n",
       "\t11 & 1062.62 \\\\\n",
       "\t12 & 910.814 \\\\\n",
       "\t13 & 1609.9 \\\\\n",
       "\t14 & 1454.11 \\\\\n",
       "\t15 & 2940.17 \\\\\n",
       "\t16 & 3661.9 \\\\\n",
       "\t17 & 3197.17 \\\\\n",
       "\t18 & 3115.94 \\\\\n",
       "\t19 & 337.561 \\\\\n",
       "\t20 & 1831.62 \\\\\n",
       "\t21 & 162.455 \\\\\n",
       "\t22 & 1655.18 \\\\\n",
       "\t23 & 2133.22 \\\\\n",
       "\t24 & 539.298 \\\\\n",
       "\t25 & 2999.43 \\\\\n",
       "\t26 & 227.704 \\\\\n",
       "\t27 & 211.724 \\\\\n",
       "\t28 & 143.813 \\\\\n",
       "\t29 & 294.284 \\\\\n",
       "\t30 & 3151.9 \\\\\n",
       "\t$\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4474×1 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m Column1   \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64   \u001b[0m\n",
       "──────┼───────────\n",
       "    1 │  1023.33\n",
       "    2 │   311.594\n",
       "    3 │   351.542\n",
       "    4 │  1609.9\n",
       "    5 │  1078.6\n",
       "    6 │   386.83\n",
       "    7 │   203.735\n",
       "    8 │   564.598\n",
       "    9 │   107.86\n",
       "   10 │  1070.61\n",
       "   11 │  1062.62\n",
       "  ⋮   │     ⋮\n",
       " 4465 │  8323.83\n",
       " 4466 │ 10236.7\n",
       " 4467 │  9275.93\n",
       " 4468 │ 10306.6\n",
       " 4469 │  9779.94\n",
       " 4470 │  9664.75\n",
       " 4471 │ 10993.7\n",
       " 4472 │ 11445.1\n",
       " 4473 │ 12117.6\n",
       " 4474 │ 13087.0\n",
       "\u001b[36m 4453 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx = CSV.read(\"x_training_stable.csv\",DataFrame)\n",
    "trainy = CSV.read(\"y_training_stable.csv\",DataFrame,header=0)\n",
    "#testx = CSV.read(\"airfoil_X_test.csv\",DataFrame)\n",
    "#testy = CSV.read(\"airfoil_Y_test.csv\",DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71913438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4474-element Vector{Float64}:\n",
       "  1023.3346\n",
       "   311.5944\n",
       "   351.5424\n",
       "  1609.9044\n",
       "  1078.596\n",
       "   386.8298\n",
       "   203.7348\n",
       "   564.5984\n",
       "   107.8596\n",
       "  1070.6064\n",
       "  1062.6168\n",
       "   910.8144\n",
       "  1609.9044\n",
       "     ⋮\n",
       " 10072.8882\n",
       "  8994.958\n",
       "  8323.8316\n",
       " 10236.675\n",
       "  9275.9256\n",
       " 10306.584\n",
       "  9779.9362\n",
       "  9664.7528\n",
       " 10993.6896\n",
       " 11445.102\n",
       " 12117.56\n",
       " 13086.9648"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxmat = Matrix(trainx)\n",
    "trainyarr = Vector(trainy[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882dc196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4474×44 Matrix{Float64}:\n",
       " 0.0  1.0  0.0  0.0  0.0  0.0  0.0  …   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     26.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  1.0  0.0  0.0  0.0  0.0  …   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0     15.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮         ⋱                  ⋮              \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0      0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0  …   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  1.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       " 0.0  0.0  0.0  0.0  1.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  …   0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0      0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  1.0      0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxmat_modified=trainxmat[:,1:4]\n",
    "trainxmat_others=trainxmat[:,5:size(trainxmat)[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e6455f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4474×4 Matrix{Float64}:\n",
       "  7.155    0.168527    33.6874  11.0\n",
       " 12.35     0.0418025   34.8216  14.0\n",
       " 10.85     0.0480043  117.581   15.0\n",
       "  9.3      0.0422563  124.439   26.0\n",
       " 12.15     0.062276    37.9532   9.0\n",
       "  9.0      0.0692291   55.9614  11.0\n",
       " 16.75     0.0137113  100.267   15.0\n",
       " 12.7929   0.0977687  142.45    28.0\n",
       "  6.385    0.140328   109.16    15.0\n",
       " 18.2      0.16296     43.5086  26.0\n",
       "  7.97     0.0400711   87.3514  11.0\n",
       "  8.71     0.139796    47.2376   4.0\n",
       "  8.85     0.112571   122.039   26.0\n",
       "  ⋮                             \n",
       " 12.7929   0.044445   245.28    28.0\n",
       " 16.75     0.0814851  258.099   11.0\n",
       " 20.25     0.0363997  219.348   11.0\n",
       " 12.7929   0.0345844  248.375   28.0\n",
       "  5.695    0.0659609  259.265    6.0\n",
       " 12.7929   0.0306933  228.035   28.0\n",
       "  6.825    0.059847   262.523   16.0\n",
       " 12.6      0.0743386  255.536    6.0\n",
       " 12.7929   0.0888399  254.267   28.0\n",
       " 12.7929  -0.969538   253.036   28.0\n",
       " 12.7929   0.0142956  242.651   28.0\n",
       " 12.7929   0.0105509  234.996   28.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxmat_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cea8c62",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: stable_all_train_val_proc not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: stable_all_train_val_proc not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[4]:1",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1116"
     ]
    }
   ],
   "source": [
    "#NOT USED\n",
    "#stable_y=stable_all_train_val_proc[:,4]\n",
    "\n",
    "#stable_x=select!(stable_all_train_val_proc,Not(:Item_Outlet_Sales))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce43942e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Cross Validation\n",
       "83 models for 15 predictors in 10 folds\n",
       "Best λ 0.000 (mean loss 0.372, std 0.009)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainxmat = Matrix(trainx)\n",
    "trainyarr = Vector(trainy[:,1])\n",
    "\n",
    "#testxmat = Matrix(testx)\n",
    "#testyarr = Vector(testy[:,1])\n",
    "\n",
    "\n",
    "#lasso_model = glmnetcv(trainxmat, trainyarr, intercept=false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff33d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample R^2 is: 0.6337612813617132\n",
      "Out sample R^2 is: 0.6377673043458182\n"
     ]
    }
   ],
   "source": [
    "#Question 1(a)\n",
    "\n",
    "trainxmat = Matrix(trainx)\n",
    "trainyarr = Vector(trainy[:,1])\n",
    "\n",
    "testxmat = Matrix(testx)\n",
    "testyarr = Vector(testy[:,1])\n",
    "\n",
    "\n",
    "lasso_model = glmnetcv(trainxmat, trainyarr, intercept=false)\n",
    "\n",
    "\n",
    "lasso_best_ind = argmin(lasso_model.meanloss)\n",
    "lasso_betas = lasso_model.path.betas[:,lasso_best_ind]\n",
    "\n",
    "irsq = lasso_model.path.dev_ratio[lasso_best_ind]\n",
    "println(\"In sample R^2 is: $irsq\")\n",
    "\n",
    "predictions = GLMNet.predict(lasso_model, testxmat)\n",
    "\n",
    "orsq = 1 - ((sum((testyarr.-predictions).^2)) / (sum((testyarr.-mean(trainyarr)).^2)))\n",
    "println(\"Out sample R^2 is: $orsq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "309f8028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more strong correlation and a total of 7 variables"
     ]
    }
   ],
   "source": [
    "#Question 1(b)\n",
    "\n",
    "cor(trainxmat)\n",
    "#It seems like correlation between variable 1 and 8 is very high, we double check\n",
    "cor(trainxmat[:,1], trainxmat[:,8])\n",
    "#True so we remove column 8\n",
    "trainxmat2 = trainxmat[:, 1:end .!= 8]\n",
    "testxmat2 = testxmat[:, 1:end .!= 8]\n",
    "\n",
    "cor(trainxmat2)\n",
    "#correlation between 2 and 5 > 0.7 so we remove 5\n",
    "trainxmat2 = trainxmat2[:, 1:end .!= 5]\n",
    "testxmat2 = testxmat2[:, 1:end .!= 5]\n",
    "\n",
    "cor(trainxmat2)\n",
    "#correlation between 2 and 9 > 0.7 so we remove 9\n",
    "trainxmat2 = trainxmat2[:, 1:end .!= 9]\n",
    "testxmat2 = testxmat2[:, 1:end .!= 9]\n",
    "\n",
    "cor(trainxmat2)\n",
    "#correlation between 2 and 9 > 0.7 so we remove 9\n",
    "trainxmat2 = trainxmat2[:, 1:end .!= 9]\n",
    "testxmat2 = testxmat2[:, 1:end .!= 9]\n",
    "\n",
    "cor(trainxmat2)\n",
    "#correlation between 2 and 11 > 0.7 so we remove 11\n",
    "trainxmat2 = trainxmat2[:, 1:end .!= 11]\n",
    "testxmat2 = testxmat2[:, 1:end .!= 11]\n",
    "\n",
    "cor(trainxmat2)\n",
    "#correlation between 3 and 9 > 0.7 so we remove 9\n",
    "trainxmat2 = trainxmat2[:, 1:end .!= 9]\n",
    "testxmat2 = testxmat2[:, 1:end .!= 9]\n",
    "\n",
    "cor(trainxmat2)\n",
    "cor(trainxmat2[:,5], trainxmat2[:,7])\n",
    "#correlation between 5 and 7 > 0.7 so we remove 7\n",
    "trainxmat2 = trainxmat2[:, 1:end .!= 7]\n",
    "testxmat2 = testxmat2[:, 1:end .!= 7]\n",
    "\n",
    "cor(trainxmat2)\n",
    "cor(trainxmat2[:,7], trainxmat2[:,8])\n",
    "#correlation between 7 and 8 > 0.7 so we remove 8\n",
    "trainxmat2 = trainxmat2[:, 1:end .!= 8]\n",
    "testxmat2 = testxmat2[:, 1:end .!= 8]\n",
    "\n",
    "cor(trainxmat2)\n",
    "\n",
    "problem = 0\n",
    "m,n = size(cor(trainxmat2))\n",
    "for i=1:m\n",
    "    for j=1:n\n",
    "        if(cor(trainxmat2)[i,j] > 0.7 && i!=j)\n",
    "            print(\"Correlation between variables $i and $j is > 0.7\")\n",
    "            problem = 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "if (problem == 0)\n",
    "    print(\"No more strong correlation and a total of $m variables\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba408625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample R^2 is: 0.559143431150576\n",
      "Out sample R^2 is: 0.5784134408726588\n"
     ]
    }
   ],
   "source": [
    "lasso_model2 = glmnetcv(trainxmat2, trainyarr, intercept=false)\n",
    "\n",
    "lasso_best_ind2 = argmin(lasso_model2.meanloss)\n",
    "lasso_betas2 = lasso_model2.path.betas[:,lasso_best_ind2]\n",
    "\n",
    "irsq2 = lasso_model2.path.dev_ratio[lasso_best_ind2]\n",
    "println(\"In sample R^2 is: $irsq2\")\n",
    "\n",
    "predictions2 = GLMNet.predict(lasso_model2, testxmat2)\n",
    "\n",
    "orsq2 = 1 - ((sum((testyarr.-predictions2).^2)) / (sum((testyarr.-mean(trainyarr)).^2)))\n",
    "println(\"Out sample R^2 is: $orsq2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2ff08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf9886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d21c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8beddcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holistic (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function holistic(x, y, weirdr, M)\n",
    "    \n",
    "    n, p = size(x)\n",
    "\n",
    "    m = Model(Gurobi.Optimizer)\n",
    "    \n",
    "    set_optimizer_attribute(m, \"OutputFlag\", 0) \n",
    "    \n",
    "    @variable(m, beta[1:p])\n",
    "    @variable(m, beta0)\n",
    "    @variable(m, z[1:p], Bin)\n",
    "    @variable(m, q[1:p] >= 0)\n",
    "    @variable(m, t[1:n] >= 0)\n",
    "    \n",
    "    @constraint(m, sum(z) <= 10)\n",
    "    pby4 = trunc(Int, 4) ##CHECK IF NOT WORKS +++++++++++++++++++++++++++++++++++++++ 4 or 1\n",
    "    @constraint(m, [i=1:pby4], sum(z[(i-1)*4+j] for j=1:4) == 1)\n",
    "    @constraint(m, z[5] == 1) #ensure visibility feature chosen\n",
    "    \n",
    "    @constraint(m, [i=1:p], -M*z[i] <= beta[i])\n",
    "    @constraint(m, [i=1:p], beta[i] <= M*z[i])\n",
    "    @constraint(m, [i=1:p], beta[i] <= q[i])\n",
    "    @constraint(m, [i=1:p], -beta[i] <= q[i])\n",
    "\n",
    "    for i=2:p\n",
    "        for j=1:(i-1)\n",
    "            if (cor(x[:,i],x[:,j]) > 0.7)\n",
    "                @constraint(m, z[i]+z[j] <= 1)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    @constraint(m, [i=1:n], (y[i] - sum(x[i,j]*beta[j] for j=1:p) - beta0) <= t[i])\n",
    "    @constraint(m, [i=1:n], -(y[i] - sum(x[i,j]*beta[j] for j=1:p) - beta0) <= t[i])\n",
    "    \n",
    "    @objective(m, Min, 0.5 * sum(t[i]^2 for i=1:n) + weirdr * sum(q[j] for j=1:p))\n",
    "    optimize!(m)\n",
    "        \n",
    "    obj = JuMP.objective_value(m)\n",
    "    beta0 = JuMP.value(beta0)\n",
    "    betas = JuMP.value.(beta)\n",
    "    z = JuMP.value.(z)\n",
    "        \n",
    "    return obj, beta0, betas, z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78df9cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creatematrices (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add origional variables back in that were not transformed\n",
    "#trainxmat=orig 4 columns\n",
    "\n",
    "function creatematrices(trainxmat,  eps)\n",
    "    ntrain, ptrain = size(trainxmat)\n",
    "    #ntest, ptest = size(testxmat)\n",
    "\n",
    "    modtrainxmat = zeros(ntrain, 4*ptrain)\n",
    "    #modtestxmat = zeros(ntest, 4*ptest)\n",
    "\n",
    "    for i = 1:(4)\n",
    "        modtrainxmat[:,4*(i-1)+1] = trainxmat[:,i]\n",
    "        modtrainxmat[:,4*(i-1)+2] = trainxmat[:,i].^2\n",
    "        modtrainxmat[:,4*(i-1)+3] = sqrt.(abs.(trainxmat[:,i]))\n",
    "        modtrainxmat[:,4*(i-1)+4] = log.(abs.(trainxmat[:,i]) .+ eps)\n",
    "\n",
    "#         modtestxmat[:,4*(i-1)+1] = testxmat[:,i]\n",
    "#         modtestxmat[:,4*(i-1)+2] = testxmat[:,i].^2\n",
    "#         modtestxmat[:,4*(i-1)+3] = sqrt.(abs.(testxmat[:,i]))\n",
    "#         modtestxmat[:,4*(i-1)+4] = log.(abs.(testxmat[:,i]) .+ eps)\n",
    "        end\n",
    "\n",
    "    return modtrainxmat #, modtestxmat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3139b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gurobi, CSV, DataFrames, JuMP, LinearAlgebra, Distributions, Random, GLMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5d8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"exttrainxmat.csv\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_four_transformed = creatematrices(trainxmat_modified,  10e-6) #removed tesstxmat\n",
    "exttrainxmat=hcat(first_four_transformed, trainxmat_others)\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "using Tables\n",
    "CSV.write(\"exttrainxmat.csv\",  Tables.table(exttrainxmat), writeheader=false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e077fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Column1</th><th>Column2</th><th>Column3</th><th>Column4</th><th>Column5</th><th>Column6</th><th>Column7</th><th>Column8</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>4,474 rows × 60 columns (omitted printing of 52 columns)</p><tr><th>1</th><td>7.155</td><td>51.194</td><td>2.67488</td><td>1.96781</td><td>0.168527</td><td>0.0284015</td><td>0.410521</td><td>-1.7806</td></tr><tr><th>2</th><td>12.35</td><td>152.522</td><td>3.51426</td><td>2.51366</td><td>0.0418025</td><td>0.00174745</td><td>0.204457</td><td>-3.17456</td></tr><tr><th>3</th><td>10.85</td><td>117.722</td><td>3.29393</td><td>2.38417</td><td>0.0480043</td><td>0.00230441</td><td>0.219099</td><td>-3.03626</td></tr><tr><th>4</th><td>9.3</td><td>86.49</td><td>3.04959</td><td>2.23002</td><td>0.0422563</td><td>0.00178559</td><td>0.205563</td><td>-3.16377</td></tr><tr><th>5</th><td>12.15</td><td>147.623</td><td>3.48569</td><td>2.49733</td><td>0.062276</td><td>0.00387831</td><td>0.249552</td><td>-2.77602</td></tr><tr><th>6</th><td>9.0</td><td>81.0</td><td>3.0</td><td>2.19723</td><td>0.0692291</td><td>0.00479266</td><td>0.263114</td><td>-2.67019</td></tr><tr><th>7</th><td>16.75</td><td>280.562</td><td>4.09268</td><td>2.8184</td><td>0.0137113</td><td>0.000187999</td><td>0.117095</td><td>-4.28881</td></tr><tr><th>8</th><td>12.7929</td><td>163.657</td><td>3.57671</td><td>2.54889</td><td>0.0977687</td><td>0.00955872</td><td>0.31268</td><td>-2.32505</td></tr><tr><th>9</th><td>6.385</td><td>40.7682</td><td>2.52686</td><td>1.85395</td><td>0.140328</td><td>0.019692</td><td>0.374604</td><td>-1.9637</td></tr><tr><th>10</th><td>18.2</td><td>331.24</td><td>4.26615</td><td>2.90142</td><td>0.16296</td><td>0.0265561</td><td>0.403684</td><td>-1.81419</td></tr><tr><th>11</th><td>7.97</td><td>63.5209</td><td>2.82312</td><td>2.07569</td><td>0.0400711</td><td>0.0016057</td><td>0.200178</td><td>-3.21685</td></tr><tr><th>12</th><td>8.71</td><td>75.8641</td><td>2.95127</td><td>2.16447</td><td>0.139796</td><td>0.0195428</td><td>0.373892</td><td>-1.9675</td></tr><tr><th>13</th><td>8.85</td><td>78.3225</td><td>2.97489</td><td>2.18042</td><td>0.112571</td><td>0.0126723</td><td>0.335516</td><td>-2.18408</td></tr><tr><th>14</th><td>8.655</td><td>74.909</td><td>2.94194</td><td>2.15814</td><td>0.0883736</td><td>0.00780989</td><td>0.297277</td><td>-2.42607</td></tr><tr><th>15</th><td>16.2</td><td>262.44</td><td>4.02492</td><td>2.78501</td><td>0.175898</td><td>0.0309401</td><td>0.419402</td><td>-1.73779</td></tr><tr><th>16</th><td>12.7929</td><td>163.657</td><td>3.57671</td><td>2.54889</td><td>0.0253541</td><td>0.000642829</td><td>0.15923</td><td>-3.67442</td></tr><tr><th>17</th><td>6.78</td><td>45.9684</td><td>2.60384</td><td>1.91398</td><td>-0.941692</td><td>0.886785</td><td>0.970408</td><td>-0.060066</td></tr><tr><th>18</th><td>7.405</td><td>54.834</td><td>2.72121</td><td>2.00216</td><td>0.159844</td><td>0.0255501</td><td>0.399805</td><td>-1.83349</td></tr><tr><th>19</th><td>17.6</td><td>309.76</td><td>4.19524</td><td>2.8679</td><td>0.127412</td><td>0.0162339</td><td>0.356949</td><td>-2.06025</td></tr><tr><th>20</th><td>8.3</td><td>68.89</td><td>2.88097</td><td>2.11626</td><td>0.0382043</td><td>0.00145957</td><td>0.195459</td><td>-3.26455</td></tr><tr><th>21</th><td>12.7929</td><td>163.657</td><td>3.57671</td><td>2.54889</td><td>0.145952</td><td>0.0213018</td><td>0.382036</td><td>-1.92441</td></tr><tr><th>22</th><td>20.7</td><td>428.49</td><td>4.54973</td><td>3.03013</td><td>0.027052</td><td>0.000731811</td><td>0.164475</td><td>-3.60962</td></tr><tr><th>23</th><td>18.0</td><td>324.0</td><td>4.24264</td><td>2.89037</td><td>0.124646</td><td>0.0155365</td><td>0.353052</td><td>-2.0822</td></tr><tr><th>24</th><td>8.935</td><td>79.8342</td><td>2.98915</td><td>2.18998</td><td>0.04041</td><td>0.00163297</td><td>0.201022</td><td>-3.20843</td></tr><tr><th>25</th><td>9.695</td><td>93.993</td><td>3.11368</td><td>2.27161</td><td>0.0292234</td><td>0.000854009</td><td>0.170949</td><td>-3.53244</td></tr><tr><th>26</th><td>16.5</td><td>272.25</td><td>4.06202</td><td>2.80336</td><td>0.0126893</td><td>0.000161019</td><td>0.112647</td><td>-4.36621</td></tr><tr><th>27</th><td>12.7929</td><td>163.657</td><td>3.57671</td><td>2.54889</td><td>0.284066</td><td>0.0806934</td><td>0.532978</td><td>-1.25851</td></tr><tr><th>28</th><td>10.5</td><td>110.25</td><td>3.24037</td><td>2.35138</td><td>0.0441396</td><td>0.0019483</td><td>0.210094</td><td>-3.12017</td></tr><tr><th>29</th><td>12.7929</td><td>163.657</td><td>3.57671</td><td>2.54889</td><td>0.0440638</td><td>0.00194162</td><td>0.209914</td><td>-3.12189</td></tr><tr><th>30</th><td>9.1</td><td>82.81</td><td>3.01662</td><td>2.20828</td><td>-1.00306</td><td>1.00613</td><td>1.00153</td><td>0.00306458</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Column1 & Column2 & Column3 & Column4 & Column5 & Column6 & Column7 & Column8 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 7.155 & 51.194 & 2.67488 & 1.96781 & 0.168527 & 0.0284015 & 0.410521 & -1.7806 & $\\dots$ \\\\\n",
       "\t2 & 12.35 & 152.522 & 3.51426 & 2.51366 & 0.0418025 & 0.00174745 & 0.204457 & -3.17456 & $\\dots$ \\\\\n",
       "\t3 & 10.85 & 117.722 & 3.29393 & 2.38417 & 0.0480043 & 0.00230441 & 0.219099 & -3.03626 & $\\dots$ \\\\\n",
       "\t4 & 9.3 & 86.49 & 3.04959 & 2.23002 & 0.0422563 & 0.00178559 & 0.205563 & -3.16377 & $\\dots$ \\\\\n",
       "\t5 & 12.15 & 147.623 & 3.48569 & 2.49733 & 0.062276 & 0.00387831 & 0.249552 & -2.77602 & $\\dots$ \\\\\n",
       "\t6 & 9.0 & 81.0 & 3.0 & 2.19723 & 0.0692291 & 0.00479266 & 0.263114 & -2.67019 & $\\dots$ \\\\\n",
       "\t7 & 16.75 & 280.562 & 4.09268 & 2.8184 & 0.0137113 & 0.000187999 & 0.117095 & -4.28881 & $\\dots$ \\\\\n",
       "\t8 & 12.7929 & 163.657 & 3.57671 & 2.54889 & 0.0977687 & 0.00955872 & 0.31268 & -2.32505 & $\\dots$ \\\\\n",
       "\t9 & 6.385 & 40.7682 & 2.52686 & 1.85395 & 0.140328 & 0.019692 & 0.374604 & -1.9637 & $\\dots$ \\\\\n",
       "\t10 & 18.2 & 331.24 & 4.26615 & 2.90142 & 0.16296 & 0.0265561 & 0.403684 & -1.81419 & $\\dots$ \\\\\n",
       "\t11 & 7.97 & 63.5209 & 2.82312 & 2.07569 & 0.0400711 & 0.0016057 & 0.200178 & -3.21685 & $\\dots$ \\\\\n",
       "\t12 & 8.71 & 75.8641 & 2.95127 & 2.16447 & 0.139796 & 0.0195428 & 0.373892 & -1.9675 & $\\dots$ \\\\\n",
       "\t13 & 8.85 & 78.3225 & 2.97489 & 2.18042 & 0.112571 & 0.0126723 & 0.335516 & -2.18408 & $\\dots$ \\\\\n",
       "\t14 & 8.655 & 74.909 & 2.94194 & 2.15814 & 0.0883736 & 0.00780989 & 0.297277 & -2.42607 & $\\dots$ \\\\\n",
       "\t15 & 16.2 & 262.44 & 4.02492 & 2.78501 & 0.175898 & 0.0309401 & 0.419402 & -1.73779 & $\\dots$ \\\\\n",
       "\t16 & 12.7929 & 163.657 & 3.57671 & 2.54889 & 0.0253541 & 0.000642829 & 0.15923 & -3.67442 & $\\dots$ \\\\\n",
       "\t17 & 6.78 & 45.9684 & 2.60384 & 1.91398 & -0.941692 & 0.886785 & 0.970408 & -0.060066 & $\\dots$ \\\\\n",
       "\t18 & 7.405 & 54.834 & 2.72121 & 2.00216 & 0.159844 & 0.0255501 & 0.399805 & -1.83349 & $\\dots$ \\\\\n",
       "\t19 & 17.6 & 309.76 & 4.19524 & 2.8679 & 0.127412 & 0.0162339 & 0.356949 & -2.06025 & $\\dots$ \\\\\n",
       "\t20 & 8.3 & 68.89 & 2.88097 & 2.11626 & 0.0382043 & 0.00145957 & 0.195459 & -3.26455 & $\\dots$ \\\\\n",
       "\t21 & 12.7929 & 163.657 & 3.57671 & 2.54889 & 0.145952 & 0.0213018 & 0.382036 & -1.92441 & $\\dots$ \\\\\n",
       "\t22 & 20.7 & 428.49 & 4.54973 & 3.03013 & 0.027052 & 0.000731811 & 0.164475 & -3.60962 & $\\dots$ \\\\\n",
       "\t23 & 18.0 & 324.0 & 4.24264 & 2.89037 & 0.124646 & 0.0155365 & 0.353052 & -2.0822 & $\\dots$ \\\\\n",
       "\t24 & 8.935 & 79.8342 & 2.98915 & 2.18998 & 0.04041 & 0.00163297 & 0.201022 & -3.20843 & $\\dots$ \\\\\n",
       "\t25 & 9.695 & 93.993 & 3.11368 & 2.27161 & 0.0292234 & 0.000854009 & 0.170949 & -3.53244 & $\\dots$ \\\\\n",
       "\t26 & 16.5 & 272.25 & 4.06202 & 2.80336 & 0.0126893 & 0.000161019 & 0.112647 & -4.36621 & $\\dots$ \\\\\n",
       "\t27 & 12.7929 & 163.657 & 3.57671 & 2.54889 & 0.284066 & 0.0806934 & 0.532978 & -1.25851 & $\\dots$ \\\\\n",
       "\t28 & 10.5 & 110.25 & 3.24037 & 2.35138 & 0.0441396 & 0.0019483 & 0.210094 & -3.12017 & $\\dots$ \\\\\n",
       "\t29 & 12.7929 & 163.657 & 3.57671 & 2.54889 & 0.0440638 & 0.00194162 & 0.209914 & -3.12189 & $\\dots$ \\\\\n",
       "\t30 & 9.1 & 82.81 & 3.01662 & 2.20828 & -1.00306 & 1.00613 & 1.00153 & 0.00306458 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4474×60 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m Column1 \u001b[0m\u001b[1m Column2  \u001b[0m\u001b[1m Column3 \u001b[0m\u001b[1m Column4 \u001b[0m\u001b[1m Column5    \u001b[0m\u001b[1m Column6     \u001b[0m\u001b[1m Column7 \u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64 \u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │  7.155    51.194   2.67488  1.96781   0.168527   0.0284015    0.410521 ⋯\n",
       "    2 │ 12.35    152.522   3.51426  2.51366   0.0418025  0.00174745   0.204457\n",
       "    3 │ 10.85    117.722   3.29393  2.38417   0.0480043  0.00230441   0.219099\n",
       "    4 │  9.3      86.49    3.04959  2.23002   0.0422563  0.00178559   0.205563\n",
       "    5 │ 12.15    147.623   3.48569  2.49733   0.062276   0.00387831   0.249552 ⋯\n",
       "    6 │  9.0      81.0     3.0      2.19723   0.0692291  0.00479266   0.263114\n",
       "    7 │ 16.75    280.562   4.09268  2.8184    0.0137113  0.000187999  0.117095\n",
       "    8 │ 12.7929  163.657   3.57671  2.54889   0.0977687  0.00955872   0.31268\n",
       "    9 │  6.385    40.7682  2.52686  1.85395   0.140328   0.019692     0.374604 ⋯\n",
       "   10 │ 18.2     331.24    4.26615  2.90142   0.16296    0.0265561    0.403684\n",
       "   11 │  7.97     63.5209  2.82312  2.07569   0.0400711  0.0016057    0.200178\n",
       "  ⋮   │    ⋮        ⋮         ⋮        ⋮         ⋮            ⋮          ⋮     ⋱\n",
       " 4465 │ 20.25    410.062   4.5      3.00816   0.0363997  0.00132494   0.190787\n",
       " 4466 │ 12.7929  163.657   3.57671  2.54889   0.0345844  0.00119608   0.185969 ⋯\n",
       " 4467 │  5.695    32.433   2.38642  1.73959   0.0659609  0.00435084   0.256829\n",
       " 4468 │ 12.7929  163.657   3.57671  2.54889   0.0306933  0.000942079  0.175195\n",
       " 4469 │  6.825    46.5806  2.61247  1.92059   0.059847   0.00358166   0.244636\n",
       " 4470 │ 12.6     158.76    3.54965  2.5337    0.0743386  0.00552622   0.272651 ⋯\n",
       " 4471 │ 12.7929  163.657   3.57671  2.54889   0.0888399  0.00789254   0.29806\n",
       " 4472 │ 12.7929  163.657   3.57671  2.54889  -0.969538   0.940004     0.984651\n",
       " 4473 │ 12.7929  163.657   3.57671  2.54889   0.0142956  0.000204363  0.119564\n",
       " 4474 │ 12.7929  163.657   3.57671  2.54889   0.0105509  0.000111323  0.102718 ⋯\n",
       "\u001b[36m                                                53 columns and 4453 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy = CSV.read(\"y_training_stable.csv\",DataFrame,header=0)\n",
    "trainyarr = Vector(trainy[:,1])\n",
    "\n",
    "exttrainxmat= CSV.read(\"exttrainxmat.csv\",DataFrame,header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72c45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7700dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a62b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1\n",
      "AB"
     ]
    }
   ],
   "source": [
    "weirdroptions = [1]\n",
    "lengthoptions = length(weirdroptions)\n",
    "savemses = zeros(lengthoptions)\n",
    "M = 10000\n",
    "\n",
    "first_four_transformed = creatematrices(trainxmat_modified,  10e-6) #removed tesstxmat\n",
    "exttrainxmat=hcat(first_four_transformed, trainxmat_others)\n",
    "#exttrainxmat = creatematrices(trainxmat_modified,  10e-6) #removed tesstxmat\n",
    "\n",
    "\n",
    "#trainyarr\n",
    "#testyarr\n",
    "\n",
    "n, p = size(exttrainxmat)\n",
    "numfolds = 3\n",
    "foldsamps = sample(1:numfolds, n, replace = true)\n",
    "\n",
    "for i = 1:numfolds\n",
    "    \n",
    "    println(\"i = $i\")\n",
    "    traintrainx = exttrainxmat[[x for x in 1:n if foldsamps[x] != i],:]\n",
    "    print(\"A\")\n",
    "    trainvalx = exttrainxmat[[x for x in 1:n if foldsamps[x] == i],:]\n",
    "    print(\"B\")\n",
    "    \n",
    "    \n",
    "    traintrainy = trainyarr[[x for x in 1:n if foldsamps[x] != i],:]\n",
    "    print(\"C\")\n",
    "    trainvaly = trainyarr[[x for x in 1:n if foldsamps[x] == i],:]\n",
    "    print(\"D\")\n",
    "    for j = 1:lengthoptions\n",
    "        println(\"j = $j\")\n",
    "        r = weirdroptions[j]\n",
    "        obj, beta0, betas, z = holistic(traintrainx, traintrainy, r, M)\n",
    "        predictions = trainvalx * betas .+ beta0\n",
    "        mse = mean((predictions .- trainvaly).^2)\n",
    "        savemses[j] = savemses[j] + mse\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e5bf70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cross_val (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M=100\n",
    "r=0.1#\n",
    "\n",
    "n, p = size(exttrainxmat)\n",
    "numfolds = 10\n",
    "foldsamps = sample(1:numfolds, n, replace = true)\n",
    "\n",
    "function cross_val(rho, fold,M)\n",
    "   # first_four_transformed = creatematrices(trainxmat_modified,  10e-6) #removed tesstxmat\n",
    "   # exttrainxmat=hcat(first_four_transformed, trainxmat_others)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    traintrainx = exttrainxmat[[x for x in 1:n if foldsamps[x] != fold],:]\n",
    "    trainvalx = exttrainxmat[[x for x in 1:n if foldsamps[x] == fold],:]\n",
    "    traintrainy = trainyarr[[x for x in 1:n if foldsamps[x] != fold],:]\n",
    "    trainvaly = trainyarr[[x for x in 1:n if foldsamps[x] == fold],:]\n",
    "    print(\"D\")\n",
    "\n",
    "\n",
    "    print(\"A\")\n",
    "    obj, beta0, betas, z = holistic(traintrainx, traintrainy, rho, M)\n",
    "    print(\"B\")\n",
    "    predictions = Matrix(trainvalx) * betas .+ beta0\n",
    "    mse = mean((predictions .- trainvaly).^2)\n",
    "    #savemses[j] = savemses[j] + mse\n",
    "    \n",
    "    return(beta0, betas, z, trainvalx, trainvaly, mse)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d15ce103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAAcademic license - for non-commercial use only - expires 2022-08-18\n",
      "B"
     ]
    }
   ],
   "source": [
    "beta0, betas, z, trainvalx, trainvaly, mse = cross_val(0.1, 1, 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6781dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop over CV, rho and folds for 10fold CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d77d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f44ab3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430-element Vector{Float64}:\n",
       " 3039.736544072305\n",
       "  743.0789994088126\n",
       " 2218.9408946997105\n",
       " 1674.316627137875\n",
       " 1373.2261597115103\n",
       " 1957.5854129906375\n",
       " 2489.480305649628\n",
       " 3926.0000671938237\n",
       "  505.4898327759055\n",
       " 1298.2523812159893\n",
       " 3255.942832548813\n",
       " 1719.2216677356441\n",
       "  477.2333865006548\n",
       "    ⋮\n",
       " 4310.05201245978\n",
       " 4243.145499767079\n",
       " 2928.431636181129\n",
       " 4618.00777791233\n",
       " 3332.850501722952\n",
       " 4849.588958104796\n",
       " 3157.16117524279\n",
       " 3683.2417934263344\n",
       " 3812.415150561054\n",
       " 2819.4656141971577\n",
       " 4586.995132834587\n",
       " 4354.6148984127585"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions = trainvalx * betas .+ beta0\n",
    "Matrix(trainvalx) * betas  .+ beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "357a7da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Int64}:\n",
       "  3\n",
       "  8\n",
       "  9\n",
       " 14\n",
       " 36\n",
       " 38\n",
       " 40\n",
       " 44\n",
       " 46\n",
       " 52"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findall(x->x==1,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ecc240f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4473-element Vector{Float64}:\n",
       "   311.5944\n",
       "   351.5424\n",
       "  1609.9044\n",
       "  1078.596\n",
       "   386.8298\n",
       "   203.7348\n",
       "   564.5984\n",
       "   107.8596\n",
       "  1070.6064\n",
       "  1062.6168\n",
       "   910.8144\n",
       "  1609.9044\n",
       "  1454.1072\n",
       "     ⋮\n",
       " 10072.8882\n",
       "  8994.958\n",
       "  8323.8316\n",
       " 10236.675\n",
       "  9275.9256\n",
       " 10306.584\n",
       "  9779.9362\n",
       "  9664.7528\n",
       " 10993.6896\n",
       " 11445.102\n",
       " 12117.56\n",
       " 13086.9648"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainyarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ea63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traintrainy = trainyarr[[x for x in 1:n if foldsamps[x] != i],:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"List of MSE: $savemses\")\n",
    "bestr = weirdroptions[argmin(savemses)]\n",
    "println(\"Best WeirdR: $bestr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb3626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see that the selected hyperparameter is at the end of the range, so check a new range\n",
    "\n",
    "weirdroptions2 = [2, 5, 9, 15, 30, 50, 100]\n",
    "lengthoptions2 = length(weirdroptions2)\n",
    "savemses2 = zeros(lengthoptions2)\n",
    "M = 10000\n",
    "\n",
    "exttrainxmat, exttestxmat = creatematrices(trainxmat, testxmat, 10e-6)\n",
    "#trainyarr\n",
    "#testyarr\n",
    "\n",
    "n, p = size(exttrainxmat)\n",
    "numfolds = 10\n",
    "foldsamps = sample(1:numfolds, n, replace = true)\n",
    "\n",
    "for i = 1:numfolds\n",
    "    \n",
    "    println(\"i = $i\")\n",
    "    traintrainx = exttrainxmat[[x for x in 1:n if foldsamps[x] != i],:]\n",
    "    trainvalx = exttrainxmat[[x for x in 1:n if foldsamps[x] == i],:]\n",
    "    traintrainy = trainyarr[[x for x in 1:n if foldsamps[x] != i],:]\n",
    "    trainvaly = trainyarr[[x for x in 1:n if foldsamps[x] == i],:]\n",
    "    \n",
    "    for j = 1:lengthoptions2\n",
    "        println(\"j = $j\")\n",
    "        r = weirdroptions2[j]\n",
    "        obj, beta0, betas, z = holistic(traintrainx, traintrainy, r, M)\n",
    "        predictions = trainvalx * betas .+ beta0\n",
    "        mse = mean((predictions .- trainvaly).^2)\n",
    "        savemses2[j] = savemses2[j] + mse\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"List of MSE: $savemses\")\n",
    "bestr = weirdroptions2[argmin(savemses2)]\n",
    "println(\"Best WeirdR: $bestr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0559bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train a final model with the chosen parameter \n",
    "\n",
    "finobj, finbeta0, finbetas, finz = holistic(exttrainxmat, trainyarr, bestr, M)\n",
    "        \n",
    "predictiontrain = exttrainxmat * finbetas .+ finbeta0\n",
    "predictiontest = exttestxmat * finbetas .+ finbeta0\n",
    "\n",
    "irsq2 = 1 - ((sum((trainyarr.-predictiontrain).^2)) / (sum((trainyarr.-mean(trainyarr)).^2)))\n",
    "println(\"In sample R^2 is: $irsq2\")\n",
    "\n",
    "orsq2 = 1 - ((sum((testyarr.-predictiontest).^2)) / (sum((testyarr.-mean(trainyarr)).^2)))\n",
    "println(\"Out sample R^2 is: $orsq2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326b485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
